# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

parameters:
  test_pool_definition: # defines the hardware pool for compilation and unit test execution.
  e2e_pool_definion: # defines the hardware pool for end-to-end test execution
  stage_name: # defines a unique identifier for all jobs in a stage (in case the jobs are added multiple times to a stage)
  environment: # defines environment variables for downstream scripts
  run_end_to_end: # if set to 'true', the end to end tests will be executed
  container: # the container name for the build
  jdk: # the jdk version to use

jobs:

- job: e2e_${{parameters.stage_name}}
  # uncomment below condition to run the e2e tests only on request.
  #condition: or(eq(variables['MODE'], 'e2e'), eq(${{parameters.run_end_to_end}}, 'true'))
  # We are running this in a separate pool
  pool: ${{parameters.e2e_pool_definition}}
  timeoutInMinutes: 240
  cancelTimeoutInMinutes: 1
  workspace:
    clean: all
  steps:
    - task: Cache@2
      inputs:
        key: $(CACHE_KEY)
        restoreKeys: $(CACHE_FALLBACK_KEY)
        path: $(MAVEN_CACHE_FOLDER)
      displayName: Cache Maven local repo
      continueOnError: true
    - task: Cache@2
      inputs:
        key: e2e-cache | flink-end-to-end-tests/**/*.java, !**/avro/**
        path: $(E2E_CACHE_FOLDER)
      displayName: Cache E2E files
      continueOnError: true
    - script: |
        echo "##vso[task.setvariable variable=JAVA_HOME]$JAVA_HOME_11_X64"
        echo "##vso[task.setvariable variable=PATH]$JAVA_HOME_11_X64/bin:$PATH"
      displayName: "Set to jdk11"
      condition: eq('${{parameters.jdk}}', 'jdk11')
    - script: |
        source ./tools/ci/maven-utils.sh
        setup_maven
      displayName: Setup Maven 3.2.5
    - script: ./tools/azure-pipelines/setup_docker.sh
      displayName: Setup Docker
    - script: ./tools/azure-pipelines/free_disk_space.sh
      displayName: Free up disk space
    - script: sudo apt-get install -y bc
    - script: ${{parameters.environment}} ./tools/ci/compile.sh
      displayName: Build Flink
    - script: ${{parameters.environment}} FLINK_DIR=`pwd`/build-target flink-end-to-end-tests/run-nightly-tests.sh
      displayName: Run e2e tests
      env:
        IT_CASE_S3_BUCKET: $(SECRET_S3_BUCKET)
        IT_CASE_S3_ACCESS_KEY: $(SECRET_S3_ACCESS_KEY)
        IT_CASE_S3_SECRET_KEY: $(SECRET_S3_SECRET_KEY)
      # upload debug artifacts
    - task: PublishPipelineArtifact@1
      condition: and(succeededOrFailed(), not(eq(variables['ARTIFACT_DIR'], '')))
      displayName: Upload Logs
      inputs:
        targetPath: $(ARTIFACT_DIR)
        artifact: logs-${{parameters.stage_name}}-e2e
        

